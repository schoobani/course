<div dir="rtl">
# ترنسفورمرها چه قابلیت‌هایی دارند؟

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter1/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter1/section3.ipynb"},
]} />

در این بخش، نگاهی به آنچه که مدل‌های ترنسفومر می‌توانند انجام دهند می‌اندازیم و اولین ابزارمان از کتابخانه‌ ترانسفورمرهای هاگینگ‌فِیس را استفاده می کنیم: تابع <span dir="ltr">`pipeline()`</span>.

<Tip>
👀 دکمه <span dir="ltr">‍<em>Open in Colab</em></span> در گوشه‌ی بالا، سمت راست را می‌بینید؟ بر روی آن کلیک کنید تا یک نوت‌بوک گوگل کولب با تمامی نمونه کدهای این بخش باز شود. این دکمه در تمامی بخش‌هایی که نمونه کد دارند، وجود خواهد داشت.

اگر می‌خواهید مثال‌ها را بصورت محلی اجرا کنید، پیشنهاد می‌کنیم به  <a href="/course/chapter0">setup</a> نگاهی بیاندازید.
</Tip>

## ترنسفورمرها همه جا هستند!

مدل‌های ترنسفورمر برای حل انواع مسئله‌های NLP، مانند نمونه‌هایی که در بخش قبلی اشاره کردیم، استفاده می‌شوند. اینجا برخی شرکت‌ها و سازمان‌هایی را می‌بینید که از هاگینگ‌فِیس و مدل‌های ترنسفورمر استفاده می‌کنند. آن‌ها همچنین با اشتراک‌گذاری مدل‌های خود با جامعه کاربران در توسعه آن مشارکت می‌کنند. 

<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG" alt="Companies using Hugging Face" width="100%">

[کتابخانه‌ی ترنسفورمرهای هاگینگ‌فِیس](https://github.com/huggingface/transformers) امکان ایجاد و استفاده از این مدل‌ها را فراهم می‌کند. [هابِ مدل‌ها](https://huggingface.co/models) شامل مدل‌های از پیش تعلیم دیده‌ای است که هرکسی می‌تواند آن‌ها را دانلود و استفاده کند. شما همچنین می‌توانید مدل‌های خودتان را روی این هاب بارگذاری کنید!

<Tip>
⚠️  هاب هاگینگ‌فِیس محدود به مدل‌های ترنسفورمر نمی‌شود. هرکسی می‌تواند هر نوع مدل یا دیتاسِتی را که می‌خواهد به اشتراک بگذارد!  یک حساب بسازید <span dir="ltr"></span> تا از تمامی قابلیت‌های موجود بهره‌مند شوید.
</Tip>

قبل از عمیق‌تر شدن درباره‌ی اینکه مدل‌های ترنسفورمر چگونه کار می‌کنند، بیایید نگاهی به چند مثال بیاندازیم که چگونه می‌توان از آن‌ها برای حل مشکلات جالب NLP استفاده کرد.

## کار با پایپ‌لاین‌ها

<Youtube id="tiZFewofSLM" />

ابتداترین شیء در کتابخانه ترنسفورمرهای هاگینگ‌فِیس تابع <span dir="ltr">‍`pipeline()`</span> است. این تابع، مدل را به گام‌های پیش‌پردازش و پس‌پردازش متصل می‌کند و به ما این امکان را می‌دهد که مستقیما هر نوع متنی را وارد و یک پاسخ قابل فهم دریافت کنیم.

<span dir="ltr">
```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```
<span>

ما حتی می‌توانیم چندین جمله را بصورت همزمان وارد کنیم!

```python
classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)
```

```python out
[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]
```

بصورت پیش‌فرض، این پایپ‌لاین یک مدل از پیش تعلیم دیده خاص را که برای تحلیل احساسات در زبان انگلیسی کوک شده است استفاده می‌کند. زمانی که شیء <span dir="ltr">`classifier`</span> را ایجاد می‌کنید، مدل دانلود و انبار می‌شود. اگر دستور را دوباره اجرا کنید، مدل انبار شده مورد استفاده قرار می‌گیرد و احتیاجی به بارگذاری دوباره مدل نخواهد بود.

زمانی که مقداری متن را برای پایپ‌لاین ارسال می‌کند، سه مرحله‌ی اصلی طی می‌شود:

1. متن به فرمت قابل درک برای مدل، پیش‌پردازش می‌شود.
2. ورودی‌های پیش‌پردازش شده به مدل ارسال می‌شوند.
3. پیش‌بینی‌های مدل پس‌پردازش می‌شوند تا برای شما قابل فهم باشند.


Some of the currently [available pipelines](https://huggingface.co/transformers/main_classes/pipelines.html) are:
برخی از [پایپ‌لاین‌های موجود فعلی](https://huggingface.co/transformers/main_classes/pipelines.html) عبارتند از:

- `feature-extraction` (نمودِ برداری یک متن را دریافت می‌کند)
- `fill-mask`
- `ner` (تشخیص موجودیت اسمی)
- `question-answering`
- `sentiment-analysis`
- `summarization`
- `text-generation`
- `translation`
- `zero-shot-classification`

بیایید به برخی از این‌ها نگاهی بیاندازیم!

## [^1]دسته‌بندی زیرو-شات

با یک مسئله سخت‌تر کارمان را آغاز می‌کنیم. شرایطی را در نظر بگیرید که می‌بایست متونی را دسته‌بندی کنیم که قبلا برچسپ‌گذاری نشده‌اند. این یک سناریوی متداول در پروژه‌های دنیای واقعی است چرا که نشانه‌گذاری متن اغلب کاری زمان‌بر و نیازمند تخصص در حوزه‌ای خاص است. در چنین شرایطی پایپ‌لاین <span dir="ltr">`zero-shot-classification`</span> بسیار قدرتمند است: به شما این امکان را می‌دهد تا مشخص کنید از کدام برچسپ‌ها برای دسته‌بندی استفاده کنید تا دیگر وابسته به برچسپ‌های مدل از پیش تعلیم دیده نباشید. قبلا دیدیم که چگونه مدل می‌تواند یک جمله را با استفاده از دو برچسپ مثبت یا منفی دسته‌بندی کنید - ولی همچنین می‌تواند متن را بر اساس هر مجموعه‌ای از برچسپ‌ها که می‌خواهید دسته‌بندی کند.

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```python out
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

این پایپ‌لاین زیرو-شات نامیده شده است چراکه شما برای استفاده از آن نیازی به کوک کردن مدل بر روی داده‌ی خود ندارید. این پایپ‌لاین می‌تواند مستقیما امتیاز احتمالات برای هر لیستی از برچسپ‌ها که می‌خواهید را بازگرداند.

<Tip>

✏️  **خودتان امتحان کنید!** با رشته‌ها و برچسپ‌های مدنظر خودتان بازی کنید تا بببینید رفتار مدل چگونه است.

</Tip>


## تولید متن

حالا بیایید ببینیم چگونه از پایپ‌لاین برای تولید متن استفاده کنیم. ایده اصلی این است که شما یک نمونه متن اولیه به مدل ارایه می‌دهید و مدل با تولید مابقی متن آن را بصورت خودکار تکمیل می‌کند. این کاری مشابه قابلیت پیش‌بینی متن است که در بسیاری از گوشی‌های موبایل وجود دارد. تولید متن نیازمند تصادف است، پس طبیعی است که نتایج شما مشابه نتایجی که اینجا می‌بینید نباشند.

```python
from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")
```

```python out
[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows — data flows of various types, as seen by the '
                    'HTTP'}]
```

می‌توانید تعداد رشته‌های متفاوت تولید شده را با استفاده از آرگومان <span dir="ltr">`num_return_sequences`</span> و طول نهایی متن تولید شده را با آرگومان  <span dir="ltr">`max_length`</span> مشخص کنید.

<Tip>

✏️  **خودتان امتحان کنید!** از آرگومان‌های <span dir="ltr">`num_return_sequences`</span> و <span dir="ltr">`max_length`</span> استفاده کنید تا دو جمله ۱۵ کلمه‌ای تولید کنید.

</Tip>


## استفاده از تمام مدل‌های هابِ هاگینگ‌فِیس در پایپ‌لاین

مثال‌های قبلی از مدل‌های پیش‌فرض برای مسئله‌های در دست استفاده کردند اما شما می‌توانید مدل خاصی را از هاب برای استفاده در پایپ‌لاین و برای مسئله‌ی مشخص- مانند تولید متن، استفاده کنید. به [Model Hub](https://huggingface.co/models) بروید و بر روی تگ متناظر در سمت چپ کلیک کنید تا فقط مدل‌های مناسب برای مسئله‌ی شما نمایش داده شوند. شما می‌بایست به صفحه‌ای شبیه [این](https://huggingface.co/models?pipeline_tag=text-generation) هدایت شوید.

بیایید مدل  <span dir="ltr">[`distilgpt2`](https://huggingface.co/distilgpt2)</span> را امتحان کنیم! به این شیوه این مدل را می‌توانیم در همان پایپ‌لاین قبلی بارگذاری کنیم:


```python
from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)
```

```python out
[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]
```

می‌توانید نتیجه‌ی جستجوی خود برای مدل را با کلیک روی تگ زبان بهبود بخشیده و مدلی را انتخاب کنید که می‌تواند در دیگر زبان‌ها متن تولید کند. هاب مدل‌ها حتی حاوی نقاط تعلیم برای مدل‌هایی است چند زبان را پشتیبانی می‌کنند.

زمانی که مدلی را با کلیک بر روی آن انتخاب کردید، خواهید دید که ابزارکی وجود دارد که به شما امکان می‌دهد آن را مستقیما بصورت آنلاین بیازمایید. با این روش می‌توانید قابلیت‌های مدل را به سرعت و قبل از دانلود آن بسنجید.

<Tip>

✏️  **خودتان امتحان کنید!** از فیلترها برای یافتن مدل تولید متن در دیگر زبان‌ها استفاده کنید. با ابزارک‌ بازی کنید و در پایپ‌لاین‌ها از آن استفاده کنید.

</Tip>

### API رابطِ

تمامی مدل‌ها را می‌توانید از طریق مرورگر خود و با استفاده از رابطِ API که روی سایت هاگینگ‌فِیس است آزمایش کنید. در این صفحه می‌توانید مستقیما متن مورد نظر خود را وارد کنید و ببینید که مدل چگونه آن را پردازش می‌کند.

رابطِ‌ API که ابزارک نیز از آن قدرت می‌گیرد، بعنوان یک محصول هزینه‌دار هم در دسترس است و اگر در فرایندهای کاری‌تان به آن نیاز داشته باشید، ممکن است کمک‌کننده باشد. برای جزییات بیشتر [صفحه‌ی قیمت‌ها](https://huggingface.co/pricing) را ببینید.

## پر کردن جاهای خالی متن

پایپ‌لاین بعدی که امتحان خواهید کرد <span dir="ltr">`fill-mask`</span> است. ایده‌ی این مسئله پر کردن جای خالی در متن ارائه شده است.

```python
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

```python out
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

آرگومان <span dir="ltr">`top_k`</span> تعداد ممکن کلماتی را کنترل می‌کند که می‌خواهید نمایش دهید. توجه کنید که مدل جای کلمه‌ی  <span dir="ltr">`<mask>`</span> را پر می‌کند که اغلب با عنوان توکن <span dir="ltr">mask</span> شناخته می‌شود. دیگر مدل‌های پرکننده‌ی جاهای خالی ممکن است توکن‌های <span dir="ltr">mask</span> متفاوتی داشته باشند و همیشه بهتر است از کلمه‌ی <span dir="ltr">mask</span> مناسب، زمانی که در بین دیگر مدل‌ها جستجو می‌کنید مطمئن شود.

<Tip>

✏️   **خودتان امتحان کنید!** بر روی هاب مدل <span dir="ltr">`bert-base-cased`</span> را جستجو کنید و کلمه‌ی <span dir="ltr">mask</span> آن را در ابزارک رابطِ API بیابید. پیش‌بینی این مدل برای جمله‌ی ما در مثال‌ <span dir="ltr">`pipeline`</span> بالا چیست؟

</Tip>

## [^2]تشخیص موجودیت اسمی

تشخیص موجودیت اسمی (<span dir="ltr">NER</span>)‌ مسئله‌ای است که مدل می‌بایست تشخیص دهد کدام بخش‌ از متن ورودی مربوط به موجودیت‌هایی مانند اشخاص، موقعیت‌ها یا سازمان‌ها است. بیایید به این مثال نگاه کنیم:

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```python out
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

در اینجا مدل به درستی تشخیص داده است که سیلوین نام یک شخص است <span dir="ltr">(PER)</span>، هاگینگ‌فِیس یک سازمان است <span dir="ltr">(ORG)</span>، و بورکلین یک موقعیت است <span dir="ltr">(LOC)</span>.

از گزینه‌ی <span dir="ltr">`grouped_entities=True`</span> در تابع ساخت پایپ‌لاین استفاده می‌کنیم تا به پایپ‌لاین بگوییم بخش‌هایی از جمله‌ را که به موجودیت یکسانی متعلق است در یک گروه قرار دهد:‌ اینجا مدل به درستی  <span dir="ltr">"Hugging"</span> و <span dir="ltr">"Face"</span> را بعنوان سازمان گروه‌بندی کرده است با وجود اینکه این نام شامل چندین واژه است. در واقع همانطوری که در فصل بعدی خواهیم دید، پیش‌پردازش، بعضی واژگان را حتی به بخش‌های کوچک‌تری نیز تقسیم می‌کند. برای نمونه واژه‌ی <span dir="ltr">Sylvain</span> به چهار بخش تقسیم می‌شود: <span dir="ltr">`##yl`</span>، <span dir="ltr">`##va`</span>، <span dir="ltr">`S`</span> و <span dir="ltr">`##in`</span>. در مرحله‌ی پس‌پردازش پایپ‌لاین بطور موفقیت‌آمیز این قطعات را در یک گروه قرار می‌دهد.

<Tip>

✏️ **خودتان امتحان کنید!** در هاب مدل‌ها، مدلی که امکان برچسب‌گذاری جزء کلام در انگلیسی را دارد (اغلب با عنوان <span dir="ltr">POS</span> کوتاه می‌شود) جستجو کنید.  پیش‌بینی این مدل برای جمله‌ای که در مثال بالا آمده چیست؟

</Tip>

## پرسش و پاسخ

پایپ‌لاین <span dir="ltr">`question-answering`</span> با استفاده از اطلاعات موجود در یک زمینه‌ خاص‌ به پرسش‌ها پاسخ می‌دهد.

```python
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

```python out
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

توجه کنید که این پایپ‌لاین با استخراج اطلاعات از یک زمینه‌ی از پیش ارایه شده کار می‌کند و پاسخ را تولید نمی‌کند.

## خلاصه‌سازی

خلاصه‌سازی مسئله‌ی کوتاه کردن یک متن به متنی کوتاه‌تر با حفظ همه‌ی (یا اغلب) جنبه‌های حائز اهمیت اشاره شده در متن است. یک مثال را باهم ببینیم:

```python
from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
"""
)
```

```python out
[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]
```

همانند تولید متن، می‌توانید <span dir="ltr">`max_length`</span>  یا <span dir="ltr">`min_length`</span> را مشخص کنید.


## ترجمه

برای ترجمه، با ارائه‌ی جفت زبان‌ها در نام مسئله می‌توانید از مدل‌ پیش‌فرض استفاده کنید (مانند <span dir="ltr">"translation_en_to_fr”</span>)، اما ساده‌ترین روش انتخاب مدلی که می‌خواهید از آن استفاده کنید در [هاب مدل‌ها](https://huggingface.co/models) است. اینجا سعی خواهیم کرد از فرانسوی به انگلیسی ترجمه کنیم:

```python
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

```python out
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

همانند تولید متن، می‌توانید <span dir="ltr">`max_length`</span>  یا <span dir="ltr">`min_length`</span> را مشخص کنید.

<Tip>

✏️ **خودتان امتحان کنید!** به دنبال مدل‌های ترجمه‌ در دیگر زبان‌ها بگردید و سعی کنید جمله‌ی قبلی را به چند زبان مختلف ترجمه کنید.

</Tip>

پایپ‌لاین‌هایی که تا اینجا نمایش داده شدند، اغلب جنبه‌ی نمایشی داشتند. آن‌ها برای مسئله‌های مشخصی برنامه‌نویسی شده‌اند و قادر به حل مسئله‌های متنوع نیستند. در فصل بعدی، خواهید آموخت که داخل تابع <span dir="ltr">`pipeline()`</span> چیست و چگونه می‌توان رفتار آن را شخصی‌سازی کرد.

[^1]: Zero-shot classification
[^2]: Named entity recognition (NER)

</div>